######################################################################################88

from collections import Counter
import pandas as pd
import numpy as np
import design_paths
import design_stats
design_paths.setup_import_paths()
import tcrdock as td2
from os import system, mkdir, remove
from os.path import exists
import itertools as it
import json
import random

from design_stats import get_designable_positions

def setup_for_protein_mpnn(
        pose,
        design_mask,
        idstring, # like a pdbid, for example
):
    ''' returns 3 dicts: parsed_chains, assigned_chains, fixed_positions
    '''

    # which chains are designable?
    #
    # assigned_chains looks like:
    #{"4YOW": [["A", "C"], ["B", "D", "E", "F"]], "3HTN": [["A", "C"], ["B"]]}
    #
    # fixed_positions looks like: (these are 1-indexed)
    #{"4YOW": {"A": [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,...
    #
    nres = len(pose['resids'])
    assert len(design_mask) == nres # list or array of True,False
    design_chains = sorted(set(r[0] for r,m in zip(pose['resids'], design_mask) if m))
    fixed_chains = sorted(set(c for c in pose['chains'] if c not in design_chains))

    assigned_chains = {idstring: [design_chains, fixed_chains]}

    fixed = {x:[] for x in pose['chains']}
    res_count = Counter()
    for r, m in zip(pose['resids'], design_mask):
        ch = r[0]
        res_count[ch] += 1
        if not m: # fixed
            fixed[ch].append(res_count[ch]) # 1-indexed!

    fixed_positions = {idstring:fixed}

    parsed_chains = {}
    cs = pose['chainseq'].split('/')
    atoms = [' N  ', ' CA ', ' C  ', ' O  ']

    for chain, seq in zip(pose['chains'], cs):
        parsed_chains['seq_chain_'+chain] = seq
        coords = {}
        for atom in atoms:
            xyzs = []
            nans = np.full(3,np.nan)
            for r in pose['resids']:
                if r[0] == chain:
                    xyzs.append(pose['coords'][r].get(atom, nans).tolist())
            coords[f'{atom.strip()}_chain_{chain}'] = xyzs
        parsed_chains['coords_chain_'+chain] = coords
    parsed_chains['name'] = idstring
    parsed_chains['num_of_chains'] = len(pose['chains'])
    parsed_chains['seq'] = ''.join(cs)


    return parsed_chains, assigned_chains, fixed_positions

def run_alphafold(
        targets,
        outprefix,
        num_recycle = 1,
        model_name = 'model_2_ptm', # want PAEs
        model_params_file = None,
        dry_run = False,
        ignore_identities = False,
):
    ''' Returns results df
    results are generated by predict_tcr_from_template_alignments.py, the
    *_final.tsv file  WITH EXTRA COLUMNS:

    model_pdbfile
    model_plddtfile
    model_paefile
    '''
    PY = design_paths.AF2_PYTHON
    EXE = design_paths.path_to_design_scripts / 'af2_wrapper.py'

    outfile = outprefix+'_targets.tsv'
    targets.to_csv(outfile, sep='\t', index=False)

    xargs = (f' --num_recycle {num_recycle} --model_names {model_name} ')
    if model_params_file is not None:
        xargs += f' --model_params_files {model_params_file} '
    if ignore_identities:
        xargs += ' --ignore_identities '
    cmd = (f'{PY} {EXE} {xargs} --targets {outfile} --outfile_prefix {outprefix} '
           f' > {outprefix}_run.log 2> {outprefix}_run.err')

    print(cmd, flush=True)
    if not dry_run:
        system(cmd)

    resultsfile = outprefix+'_final.tsv'
    assert exists(resultsfile), 'run_alphafold failed '+outprefix

    dfl = []
    for _,l in pd.read_table(resultsfile).iterrows():
        outl = l.copy()
        pdbfile = l[model_name+'_pdb_file']
        plddtfile = l[model_name+'_plddt_file']
        paefile   = l[model_name+'_predicted_aligned_error_file']
        assert exists(pdbfile) and exists(paefile)
        outl['model_pdbfile'] = pdbfile
        outl['model_plddtfile'] = plddtfile
        outl['model_paefile'] = paefile
        dfl.append(outl)

    return pd.DataFrame(dfl)


def run_mpnn(
        targets,
        outprefix,
        num_mpnn_seqs=3,
        extend_flex=1,
        constant_seed=None,
        dry_run=False,
):
    ''' Returns results df

    targets has to have the columns below

    '''
    required_cols = 'targetid chainseq model_pdbfile'.split()
    for col in required_cols:
        assert col in targets.columns

    # need one of these to figure out which positions are designable
    assert ('template_0_target_to_template_alignstring' in targets.columns or
            'designable_positions' in targets.columns)

    outdir = outprefix+'_mpnn/'
    if not exists(outdir):
        mkdir(outdir)

    parsed_chains, assigned_chains, fixed_positions = [], {}, {}

    for l in targets.itertuples():
        nres = len(l.chainseq.replace('/',''))
        flex_posl = get_designable_positions(row=l, extend_flex=extend_flex)
        design_mask = np.full((nres,), False)
        design_mask[flex_posl] = True

        cs = l.chainseq.split('/')
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs))
        pose = td2.pdblite.pose_from_pdb(l.model_pdbfile)
        assert pose['sequence'] == ''.join(cs)
        pose = td2.pdblite.set_chainbounds_and_renumber(pose, chainbounds)
        assert len(pose['sequence']) == nres

        pc, ac, fp = setup_for_protein_mpnn(pose, design_mask, l.targetid)
        parsed_chains.append(pc)
        assigned_chains.update(ac)
        fixed_positions.update(fp)

    assigned_chains = [assigned_chains]
    fixed_positions = [fixed_positions]

    for vals, tag in zip([parsed_chains, assigned_chains, fixed_positions],
                         ['pc','ac','fp']):
        outfile = f'{outprefix}_{tag}.jsonl'
        with open(outfile,'w') as f:
            for val in vals:
                f.write(json.dumps(val) + '\n')

    seedarg = '' if constant_seed is None else f' --seed {constant_seed} '

    cmd = (f'{design_paths.MPNN_PYTHON} {design_paths.MPNN_SCRIPT} '
           f' --jsonl_path            {outprefix}_pc.jsonl '
           f' --chain_id_jsonl        {outprefix}_ac.jsonl '
           f' --fixed_positions_jsonl {outprefix}_fp.jsonl '
           f' --out_folder {outdir} --num_seq_per_target {num_mpnn_seqs} '
           f' --sampling_temp "0.1" '
           f' {seedarg} --batch_size 1 > {outprefix}_run.log '
           f' 2> {outprefix}_run.err')
    print(cmd, flush=True)
    if not dry_run:
        system(cmd)

    # now setup new targets array with redesigned sequences
    dfl = []
    for _, l in targets.iterrows():
        nres = len(l.chainseq.replace('/',''))
        flex_posl = get_designable_positions(row=l, extend_flex=extend_flex)
        design_mask = np.full((nres,), False)
        design_mask[flex_posl] = True
        cs = l.chainseq.split('/')
        old_fullseq = ''.join(cs)
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs))

        fastafile = f'{outdir}/seqs/{l.targetid}.fa'
        with open(fastafile,'r') as f:
            fasta = f.read()
        seqs = [x for x in fasta.split('\n') if x and x[0] != '>'][1:]
        assert len(seqs) == num_mpnn_seqs
        seq_counts = Counter(seqs)
        _, top_count = seq_counts.most_common(1)[0]
        if dry_run: # hacking!!!
            top_seq = [x for x,y in seq_counts.most_common()
                       if y==top_count][0]
        else:
            # should use constant_seed here also to eliminate randomness!
            if constant_seed:
                print('run_mpnn: still some randomness in random.choice!')
            top_seq = random.choice([x for x,y in seq_counts.most_common()
                                     if y==top_count])
        top_seqs = top_seq.split('/')
        def seq_match_score(seq1, seq2):
            return 100*abs(len(seq1)-len(seq2)) + sum(x!=y for x,y in zip(seq1,seq2))
        for top_seq in top_seqs:
            ch = min(enumerate(cs), key=lambda x:seq_match_score(x[1],top_seq))[0]
            old_seq = cs[ch]
            assert len(old_seq) == len(top_seq)
            start = chainbounds[ch]
            assert all(((a==b) or c)
                       for a,b,c in zip(old_seq, top_seq, design_mask[start:]))
            cs[ch] = top_seq

        new_fullseq = ''.join(cs)
        outl = l.copy()
        outl['chainseq'] = '/'.join(cs) # update with designed sequence

        ## update cdr3 information in the output row
        if hasattr(l, 'cdr3a'):
            assert old_fullseq.count(l.cdr3a) == 1
            start = old_fullseq.index(l.cdr3a)
            new_cdr3a = new_fullseq[start:start+len(l.cdr3a)]
            outl['cdr3a'] = new_cdr3a

            assert old_fullseq.count(l.cdr3b) == 1
            start = old_fullseq.index(l.cdr3b)
            new_cdr3b = new_fullseq[start:start+len(l.cdr3b)]
            outl['cdr3b'] = new_cdr3b

        dfl.append(outl)

    targets = pd.DataFrame(dfl)
    return targets # same as starting targets except for chainseq column



def encode_target_for_rf_ab(
        pmhc_pose,
        va_seq,
        vb_seq,
        ):

    from rf_ab_chemical import aa2long, one_letter
    aa2int = {aa:i for i,aa in enumerate(one_letter)}
    cbs = pmhc_pose['chainbounds']
    assert len(cbs) in [3,4]
    mhc_class = len(cbs) - 2
    nres_mhc = cbs[-2]
    nres = cbs[-1]
    nres_peptide = cbs[-1] - cbs[-2]

    #In [36]: info.keys()
    #Out[36]: dict_keys(['T', 'Hseq', 'Lseq', 'hotspots'])
    # based on xtal_3qiu encoding, Hseq is the alpha chain and Lseq is the beta chain
    info = {'Hseq':va_seq, 'Lseq':vb_seq, 'hotspots':[False]*nres}

    #In [26]: info['T'].keys()
    #Out[26]: dict_keys(['xyz', 'seq', 'pdb_idx', 'idx', 'cdr_bool', 'mask'])
    tinfo = {}
    tinfo['idx'] = list(range(nres))
    if mhc_class==1:
        chains = ['A']*nres_mhc + ['B']*nres_peptide
    else:
        chains = ['A']*cbs[1] + ['B']*(cbs[2]-cbs[1]) + ['C']*nres_peptide
    tinfo['pdb_idx'] = list(zip(chains, map(str, tinfo['idx'])))
    tinfo['cdr_bool'] = [False]*nres
    tinfo['seq'] = [aa2int[x] for x in pmhc_pose['sequence']]
    tinfo['xyz'] = []
    tinfo['mask'] = []
    for ii, (r,aa) in enumerate(zip(pmhc_pose['resids'], pmhc_pose['sequence'])):
        iaa = aa2int[aa]
        atom_names = aa2long[iaa]
        assert len(atom_names) == 27
        ii_xyz = [[np.nan, np.nan, np.nan] for _ in range(len(atom_names))]
        ii_mask = [False]*len(atom_names)
        for atom, v in pmhc_pose['coords'][r].items():
            if atom in atom_names:
                idx = atom_names.index(atom)
                for k in range(3):
                    ii_xyz[idx][k] = v[k]
                ii_mask[idx] = True
            else:
                print('unrecognized atom_name:', atom, aa)
        tinfo['xyz'].append(ii_xyz)
        tinfo['mask'].append(ii_mask)

    info['T'] = tinfo
    return info




def run_rf_antibody_on_designs(
        targets,
        outprefix,
        # useful if mpnn made chainseq, pdbseq is old:
        allow_pdb_chainseq_mismatch_for_tcr=False,
        dry_run = False,
        delete_old_results = False,
):
    required_cols = 'targetid chainseq model_pdbfile'.split()
    for col in required_cols:
        assert col in targets.columns

    assert targets.targetid.value_counts().max()==1 # unique

    assert exists(design_paths.RFAB_PYTHON)
    assert exists(design_paths.RFAB_SCRIPT)

    all_info = {}
    for l in targets.itertuples():
        print('encode:', l.targetid)
        pose = td2.pdblite.pose_from_pdb(l.model_pdbfile)
        #assert len(pose['chains']) == 1 # not if coming from rf_ab_diff pipeline?
        cs = l.chainseq.split('/')
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs))
        if not allow_pdb_chainseq_mismatch_for_tcr:
            assert pose['sequence'] == ''.join(cs)
        else:
            nres_pmhc = chainbounds[-3]
            assert pose['sequence'][:nres_pmhc] == ''.join(cs)[:nres_pmhc]

        pose = td2.pdblite.set_chainbounds_and_renumber(pose, chainbounds)
        nchains = len(pose['chains'])
        pmhc_pose = td2.pdblite.delete_chains(pose, [nchains-2, nchains-1])

        info = encode_target_for_rf_ab(pmhc_pose, cs[-2], cs[-1])
        all_info[l.targetid] = info


    outdir = outprefix+'_rfab/'
    if not exists(outdir):
        mkdir(outdir)

    outfile = f'{outdir}rfab_targets.json'
    with open(outfile, 'w') as f:
        f.write(json.dumps(all_info)+'\n')
    print('made:', outfile)

    if delete_old_results:
        for targetid in targets.targetid:
            pdbfile = f'{outdir}{targetid}_best.pdb'
            if exists(pdbfile):
                print('WARNING removing old rf_antibody pdbfile:', pdbfile)
                remove(pdbfile)
            resfile = f'{outdir}{targetid}.npz' # results
            if exists(resfile):
                print('WARNING removing old rf_antibody resfile:', resfile)
                remove(pdbfile)



    cmd = (f'{design_paths.RFAB_PYTHON} {design_paths.RFAB_SCRIPT} '
           f' --model_path {design_paths.RFAB_CHK} '
           f' --mask_ab_sidechains --mask_target_sidechains '
           f' --num_recycles 10 --max_crop 1000 --output_path {outdir} '
           f' --sequence_json {outfile} > {outprefix}.log 2> {outprefix}.err')
    print(cmd)
    if not dry_run:
        system(cmd)


    dfl = []
    for _, l in targets.iterrows():
        pdbfile = f'{outdir}{l.targetid}_best.pdb'
        resfile = f'{outdir}{l.targetid}.npz' # results
        assert exists(pdbfile) and exists(resfile), \
            f'rf_antibody failed for target: {l.targetid}'

        res = np.load(resfile)

        pose = td2.pdblite.pose_from_pdb(pdbfile)
        assert pose['sequence'] == l.chainseq.replace('/','')

        cbs = [0] + list(it.accumulate(len(x) for x in l.chainseq.split('/')))

        pose = td2.pdblite.set_chainbounds_and_renumber(pose, cbs)
        outl = l.copy()
        outl['old_model_pdbfile'] = l.model_pdbfile
        outl['model_pdbfile'] = pdbfile

        outl['rfab_pbind'] = res['p_bind'][0]
        outl['rfab_pmhc_tcr_pae'] = res['pae_interaction']

        dginfo = design_stats.compute_docking_geometry_info(l, pose=pose)
        if dginfo is not None:
            for k,v in dginfo.items():
                outl[k] = v

        dfl.append(outl)

    results = pd.DataFrame(dfl)
    return results

def setup_rf_diff_tcr_template(pdbid, nterm_seq_stem=3, cterm_seq_stem=2):
    ''' returns:

    tcr_template_pdbfile, design_loops

    design_loops looks like ['H1:5', 'H2:6', 'H3:15', 'L1:4', 'L2:7', 'L3:18']

    note that H is TCR alpha chain and L is TCR beta chain !!

    '''
    outfile = (f'{td2.util.path_to_db}/rf_diff_templates/'
               f'{pdbid}_tcr_n{nterm_seq_stem}_c{cterm_seq_stem}.pdb')

    all_ternary_info = pd.concat([td2.sequtil.ternary_info,
                                  td2.sequtil.new_ternary_info])
    row = all_ternary_info.loc[pdbid]
    print('setup_rf_diff_tcr_template:', pdbid, outfile)

    pdbfile = str(td2.util.path_to_db / row.pdbfile)
    pose = td2.pdblite.pose_from_pdb(pdbfile)

    tdifile = pdbfile+'.tcrdock_info.json'
    with open(tdifile, 'r') as f:
        tdinfo = td2.tcrdock_info.TCRdockInfo().from_string(f.read())

    nres_pmhc = pose['chainbounds'][2]
    tdinfo.delete_residue_range(0, nres_pmhc)
    pose = td2.pdblite.delete_chains(pose, [0,1])
    _, nres_tcra, nres = pose['chainbounds']

    resids = ([('H', f'{i:4d} ') for i in range(1, nres_tcra+1)]+
              [('L', f'{i:4d} ') for i in range(nres_tcra+1, nres+1)])
    coords = {newr: pose['coords'][oldr]
              for oldr, newr in zip(pose['resids'], resids)}
    pose['resids'] = resids
    pose['coords'] = coords
    pose = td2.pdblite.update_derived_data(pose)

    if not exists(outfile):
        td2.pdblite.dump_pdb(pose, outfile)
        print('made:', outfile)
        out = open(outfile, 'a')
    else:
        out = None

    design_loops = []
    for ii, loop in enumerate(tdinfo.tcr_cdrs):
        if ii in [2,6]:
            continue
        hl = 'H' if ii<4 else 'L'
        num = ii%4 + 1
        start, stop = loop
        if num == 4:
            num = 3
            start += nterm_seq_stem
            stop -= cterm_seq_stem

        if out is not None:
            for pos in range(start, stop+1):
                out.write(f'REMARK PDBinfo-LABEL: {pos+1:4d} {hl}{num}\n')
        print('cdr', hl, num, pose['sequence'][start:stop+1])

        looplen = stop-start+1
        design_loops.append(f'{hl}{num}:{looplen}')

    if out is not None:
        out.close()

    return outfile, design_loops


def setup_rf_diff_pmhc_template(pdbid, n_hotspot=3):
    ''' returns

    pdbfile, hotspot_string
    '''

    outfile = f'{td2.util.path_to_db}/rf_diff_templates/{pdbid}_pmhc_hs{n_hotspot}.pdb'

    all_ternary_info = pd.concat([td2.sequtil.ternary_info,
                                  td2.sequtil.new_ternary_info])
    row = all_ternary_info.loc[pdbid]
    cbs = [0]+list(it.accumulate(len(x) for x in row.chainseq.split('/')))
    assert len(cbs) == row.mhc_class + 4 # == num_chains + 1
    nres_mhc = cbs[-4]

    # 1-indexed numbers
    # start at the fourth peptide position (skip the first 3)
    hotspot_string = '[' + ','.join(f'T{nres_mhc+4+i}' for i in range(n_hotspot)) + ']'

    if not exists(outfile):
        # make target pdbfile
        pdbfile = td2.util.path_to_db / row.pdbfile
        pose = td2.pdblite.pose_from_pdb(pdbfile)
        pose = td2.pdblite.delete_chains(pose, [2,3])
        nres = len(pose['sequence'])
        resids = [('T', f'{i:4d} ') for i in range(1, nres+1)]
        coords = {newr: pose['coords'][oldr]
                  for oldr, newr in zip(pose['resids'], resids)}
        pose['resids'] = resids
        pose['coords'] = coords
        pose = td2.pdblite.update_derived_data(pose)

        td2.pdblite.dump_pdb(pose, outfile)
        print('made:', outfile)

    return outfile, hotspot_string


def setup_extra_pmhc_templates(pmhcs, outfile_prefix):
    ''' This is for adding additional pMHC templates into the AF2 modeling
    See dock_design.py for an example
    '''
    import tcrdock.setup
    required_cols = 'organism mhc_class pdbfile pdbid'.split()
    dfl = []

    seen = set()
    for _, l in pmhcs.iterrows():
        if l.pdbfile in seen:
            continue
        seen.add(l.pdbfile)

        pose, tdinfo = td2.setup.load_and_setup_tcrdock_pose(
            l.pdbfile, l.organism, l.mhc_class, pmhc_only=True
        )

        new_pdbfile = f'{outfile_prefix}{l.pdbid}_orient.pdb'
        td2.pdblite.dump_pdb(pose, new_pdbfile)
        print('made:', new_pdbfile)
        tdifile = new_pdbfile+'.tcrdock_info.json'
        with open(tdifile, 'w') as f:
            f.write(tdinfo.to_string())
            print('made:', tdifile)

        mhc_seq, tmp = pose['chainseq'].split('/')
        assert tmp == tdinfo.pep_seq

        mhc_alignseq = td2.sequtil.get_mhc_class_1_mhc_alignseq_from_chainseq(
            tdinfo.mhc_allele, mhc_seq, info=l.pdbfile)

        breaks, totals = td2.pdblite.find_chainbreaks(
            pose, return_total_chainbreak_by_chain=True)

        mhc_total_chainbreak = sum(totals[:l.mhc_class])
        pep_chainbreak = totals[l.mhc_class]
        assert pep_chainbreak < 1e-2

        mhc = ':'.join(tdinfo.mhc_allele.split(':')[:2]) # trim extra ":01:01" junk
        outl = dict(
            organism=l.organism,
            mhc_class=l.mhc_class,
            mhc_allele=mhc,
            pep_seq=tdinfo.pep_seq,
            pdbfile = new_pdbfile,
            chainseq = pose['chainseq'],
            mhc_alignseq=mhc_alignseq,
            mhc_total_chainbreak = mhc_total_chainbreak,
            pdbid=l.pdbid,
        )
        dfl.append(outl)

    extra_pmhc_templates = pd.DataFrame(dfl).set_index('pdbid', drop=False)
    return extra_pmhc_templates


if __name__ == '__main__':
    pmhcs = pd.DataFrame([dict(
        organism = 'human',
        mhc_class = 1,
        pdbfile = '/home/pbradley/csdat/tcrpepmhc/amir/A2-PAP.pdb',
        pdbid = 'a2pp',
    )])
    extra_pmhc_templates = setup_extra_pmhc_templates(pmhcs, 'tmptest')
    print(extra_pmhc_templates.iloc[0])
    exit()


if __name__ == '__main__':

    pdbids = ['1oga','3o4l','3gsn']

    for pdbid in pdbids:
        fname, design_loops = setup_rf_diff_tcr_template(pdbid)
        print('design_loops:', pdbid, design_loops)


        fname, hotspot_string = setup_rf_diff_pmhc_template(pdbid)
        print('hotspot_string:', pdbid, hotspot_string)



